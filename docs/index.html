
<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="Guiding Token-Sparse Diffusion Models">
    <meta name="keywords" content="Sparse Guidance, Token Sparsity, Diffusion, Guidance, ImageNet-256, Text-to-Image">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Guiding Token-Sparse Diffusion Models</title>
    <style>
        .container.is-max-desktop {
            max-width: 1300px;
        }

        .table-images {
            display: flex;
            flex-wrap: nowrap;
            gap: 0.75rem;
            justify-content: center;
            overflow-x: auto;
            padding-bottom: 0.5rem;
        }

        .table-images img {
            flex: 0 0 49%;
            max-width: none;
            height: auto;
            object-fit: contain;
            display: block;
            min-width: 320px;
        }

        .figcaption-italic {
            color: #777;
            font-size: 0.85em;
            margin-top: 0.5rem;
        }
    </style>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1FWSVCGZTG"></script>
    <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-1FWSVCGZTG');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/twentytwenty.css">
    <link rel="stylesheet" href="static/css/index.css">
    <link rel="icon" href="static/figures/badge-website.svg">

    <script src="static/js/jquery-3.2.1.min.js"></script>
    <script src="static/js/jquery.event.move.js"></script>
    <script src="static/js/jquery.twentytwenty.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/fontawesome.all.min.js"></script>

    <!--MathJax-->
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Guiding Token-Sparse Diffusion Models</h1>
                        <!-- <h2 class="title is-3">Project Page</h2> -->
                        <div class="is-size-5 publication-authors">
                            <span class="author-block" style="margin-right: 10px;">Felix Krause,</span>
                            <span class="author-block" style="margin-right: 10px;">Stefan Andreas Baumann,</span>
                            <span class="author-block" style="margin-right: 10px;">Johannes Schusterbauer,</span>
                            <span class="author-block" style="margin-right: 10px;">Olga Grebenkova,</span>
                            <span class="author-block" style="margin-right: 10px;">Ming Gui,</span>
                            <span class="author-block" style="margin-right: 10px;">Vincent Tao Hu,</span>
                            <span class="author-block" style="margin-right: 10px;">Björn Ommer</span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"></span><br>
                            <span class="author-block">CompVis @ LMU Munich</span><br>
                            <span class="author-block"> Munich Center for Machine Learning (MCML)</span><br>
                        </div>


                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2601.01608" target="_blank" rel="noopener noreferrer"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf" style="color: orangered"></i>
                                        </span>
                                        <span>PDF</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://github.com/CompVis/tread" target="_blank" rel="noopener noreferrer"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div style="text-align: center;">
                <img id="teaser" width="90%" src="static/images/title_fig.png"
                    alt="Sparse Guidance overview and headline results." />
            </div>
            </div>
        </div>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <div class="content has-text-justified">
                        <p style="margin-bottom: 20px; margin-top: 10px;">
                            <span style="font-weight: bold; font-size: 1.3em;">TL;DR:</span> Token-sparse diffusion models (masking / routing) train fast
                            and can be strong conditionals — but <em>Classifier-free Guidance (CFG)</em> often breaks at inference. We introduce
                            <strong>Sparse Guidance (SG)</strong>, a finetune-free guidance rule that uses <em>token sparsity</em> as the guidance signal:
                            combine a <em>strong</em> low-sparsity conditional prediction with a <em>weak</em> high-sparsity conditional prediction.
                            On ImageNet-256, SG reaches <strong>1.58 FID</strong> with <strong>25%</strong> fewer FLOPs and enables up to
                            <strong>58%</strong> FLOP savings at matched baseline quality. SG also scales to a <strong>2.5B</strong> text-to-image model,
                            improving human preference and throughput.
                        </p> <br>
                    </div>
                </div>
            </div>
        </div>
    </section>



    <section class="section pt-0  hero is-light">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <br>
                    <h2 class="title is-3">Overview</h2>
                    <div class="content has-text-justified">
                        <p>
                            Diffusion models deliver high-quality image synthesis but remain expensive. Token sparsity methods reduce costs by
                            processing only a subset of tokens (masking or routing), improving training throughput and often strengthening the
                            conditional model. However, in practice these models struggle at inference because they respond poorly to
                            Classifier-free Guidance (CFG), limiting achievable fidelity and slowing adoption.
                        </p>
                        <p>
                            We propose <strong>Sparse Guidance (SG)</strong>: instead of using conditional dropout as the guidance signal, SG uses
                            <em>token-level sparsity</em> to create a controllable <em>capacity gap</em> between two conditional predictions. This preserves
                            the variance of the conditional prediction (reducing CFG-style collapse) while improving fidelity — and it lets us trade
                            compute for quality at test time.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Motivation: When CFG Fails</h2>
	                    <div class="content has-text-justified">
	                        <p>
	                            Token-sparse training can yield strong conditionals, but CFG relies on an unconditional branch that behaves
	                            differently from the conditional prediction. Under token sparsity, this relationship often breaks: CFG gains shrink,
	                            and sometimes samples become unstable or collapse.
	                        </p>
		                        <figure>
		                            <img style="width: 100%; margin-left: auto; margin-right: auto; display: block;"
		                                src="static/images/motivation_fig.png"
		                                alt="CFG provides limited benefits for token-sparse diffusion models; Sparse Guidance restores strong guidance gains." />
		                            <figcaption class="has-text-centered figcaption-italic">
		                                CFG provides limited benefits for token-sparse diffusion models; Sparse Guidance (SG) restores strong guidance gains.
		                            </figcaption>
		                        </figure>
	                    </div>
	                </div>
	            </div>
	        </div>
	    </section>

    <section class="section pt-0 hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <br>
                    <h2 class="title is-3">Token Sparsity: Masking vs Routing</h2>
                    <div class="content has-text-justified">
                        <p>
                            We study Sparse Guidance on two common token-sparsity mechanisms. <em>Masking</em> permanently drops a fraction of tokens
                            (optionally replacing them with a learned “mask” embedding). <em>Routing</em> skips computation for selected tokens in a
                            subset of layers and later reinserts them unchanged, preserving instance-specific information.
                        </p>
	                        <figure>
	                            <img style="width: 100%; margin-left: auto; margin-right: auto; display: block;"
	                                src="static/images/routing_v_masking.png"
	                                alt="Masking drops tokens; routing skips compute and reinserts tokens." />
	                            <figcaption class="has-text-centered figcaption-italic">
	                                Masking drops tokens; routing skips compute and reinserts tokens later.
	                            </figcaption>
	                        </figure>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method: Sparse Guidance</h2>
                    <div class="content has-text-justified">
                        <p>
                            Sparse Guidance revisits sparsity as a <em>test-time control signal</em>. We evaluate the same network under two different
                            sparsity rates: a low-sparsity <em>strong</em> branch and a high-sparsity <em>weak</em> branch. Both predictions are
                            conditional, and the guidance signal comes purely from the <em>capacity gap</em> induced by sparsity.
                        <p class="has-text-centered" style="overflow-x: auto; padding: 1rem 0;">
                            <span style="display: inline-block; min-width: max-content;">
                                $$D^{\text{strong}}_{\theta}(c) := D_{\theta}(x_t, t, c; \gamma_{\text{strong}}), \quad
                                D^{\text{weak}}_{\theta}(c) := D_{\theta}(x_t, t, c; \gamma_{\text{weak}}), \quad
                                0 \le \gamma_{\text{strong}} < \gamma_{\text{weak}} < 1.$$
                            </span>
                            <br>
                            <span style="display: inline-block; min-width: max-content;">
                                $$D^{\text{SG}}_{\theta}(c, \gamma_{\text{strong}}, \gamma_{\text{weak}}, \omega)
                                = \omega\, D^{\text{strong}}_{\theta}(c) + (1-\omega)\, D^{\text{weak}}_{\theta}(c).$$
                            </span>
                        </p>
                        <p>
                            Intuitively: increasing sparsity lowers effective capacity and softens the conditional distribution; decreasing sparsity
                            yields a sharper, higher-capacity predictor. SG uses the weak branch to steer the strong one, while staying closer to the
                            conditional prediction than CFG typically does.
                        </p>
	                        <figure>
	                            <img style="width: 85%; margin-left: auto; margin-right: auto; display: block;"
	                                src="static/images/naive_solution.png"
	                                alt="Naively applying inference-time sparsity degrades outputs as sparsity increases." />
	                            <figcaption class="has-text-centered figcaption-italic">
	                                Naively applying inference-time sparsity (without SG) degrades quality as sparsity increases.
	                            </figcaption>
	                        </figure>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section pt-0 hero is-light">
        <div class="hero-body">
            <div class="container">
                <div class="columns is-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3 has-text-centered">Results</h2>

	                        <div class="content has-text-justified">
	                            <h3 class="title has-text-centered" style="font-size: 1.5em;">ImageNet-256: Quality–Compute Trade-off</h3>
	                            <p>
	                                SG gives a simple knob between <em>quality</em> and <em>speed</em>. In our ImageNet-256 experiments, SG reaches
	                                <strong>1.58 FID</strong> (SG<sub>FID</sub>) and also provides a fast configuration (SG<sub>FLOPS</sub>) that achieves
	                                large compute savings while remaining competitive in fidelity.
	                            </p>
		                            <figure>
		                                <div style="display: flex; flex-direction: column; gap: 1rem; align-items: center;">
		                                    <img src="static/images/imgnet_guidance_failures.png"
		                                        alt="SG outperforms other guidance methods in FID and GFLOPs." />
		                                    <img src="static/images/imgnet_fid.png"
		                                        alt="State-of-the-art comparison on ImageNet-256; SG reaches 1.58 FID." />
		                                </div>
		                                <figcaption class="has-text-centered figcaption-italic">
		                                    Left: SG improves both fidelity (FID) and inference compute compared to alternative guidance methods.
		                                    Right: state-of-the-art comparison on ImageNet-256 (FID / sFID / IS / Precision / Recall).
		                                </figcaption>
		                            </figure>
	                        </div>
	                        <div class="content has-text-justified">
	                            <h3 class="title has-text-centered" style="font-size: 1.5em;">Robust Hyperparameters & Sparsity Scheduling</h3>
	                            <p>
	                                SG is well-behaved across a wide range of guidance scales ω when we tune the sparsity pair
	                                (γ<sub>strong</sub>, γ<sub>weak</sub>). Larger ω consistently tolerates higher total sparsity, enabling higher throughput
	                                at matched quality.
	                            </p>
		                            <figure>
		                                <img style="width: 100%; margin: auto; display: block; max-width: none;" src="static/images/heatmaps1.png"
		                                    alt="FID heatmaps over (gamma_strong, gamma_weak) across different guidance scales omega." />
		                                <figcaption class="has-text-centered figcaption-italic">
		                                    FID heatmaps over (γ<sub>strong</sub>, γ<sub>weak</sub>) for ω ∈ {1.3, 1.5, 1.7, 1.9}.
		                                </figcaption>
		                            </figure>

                            <h4 class="title is-4" style="margin-top: 1.25rem;">Practical Usage</h4>
                            <ol style="text-align: left; margin-left: 1.25rem;">
                                <li>Pick a clear capacity gap: start with γ<sub>strong</sub> &lt; γ<sub>weak</sub> (e.g., 0.4–0.6 vs 0.6–0.8).</li>
                                <li>Increase ω and sparsity together for speed: larger ω supports higher (γ<sub>strong</sub>, γ<sub>weak</sub>).</li>
                                <li>Prefer routing when available: it preserves instance information and is less sensitive to hyperparameters.</li>
                            </ol>
                        </div>

	                    </div>
	                </div>
	            </div>
	        </div>
	    </section>

	    <section class="section">
	        <div class="container is-max-desktop">
	            <div class="columns is-centered has-text-centered">
	                <div class="column is-four-fifths">
	                    <h2 class="title is-3">Text-to-Image Results</h2>
	                    <div class="content has-text-justified">
		                        <p>
		                            We apply SG to a <strong>2.5B</strong> text-to-image Diffusion Transformer trained with routing sparsity. SG improves
		                            human preference (HPSv3) across categories and increases throughput (0.32 → 0.49 images/s on an H200 GPU).
		                        </p>
		                        <figure>
		                            <img style="width: 100%; margin: 0 auto; display: block;" src="static/images/t2i_hpsv3.png"
		                                alt="HPSv3 results for TR-DiT-2.5B, showing improvements from SG over CFG and unguided." />
		                            <figcaption class="has-text-centered figcaption-italic">
		                                HPSv3 scores for TR-DiT-2.5B: SG improves over CFG across categories and increases throughput.
		                            </figcaption>
		                        </figure>
		                        <figure>
		                            <img style="width: 100%; margin: 0 auto; display: block;" src="static/images/t2i_sg_examples.png"
		                                alt="Selected text-to-image examples comparing conditional prediction, CFG, and SG." />
		                            <figcaption class="has-text-centered figcaption-italic">
		                                Selected examples: SG keeps more of the conditional structure while staying faithful to the prompt.
		                            </figcaption>
		                        </figure>
	                    </div>
	                </div>
	            </div>
	        </div>
    </section>
      
      
      


    <!--BibTex citation -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@misc{krause2026guidingtokensparsediffusionmodels,
      title={Guiding Token-Sparse Diffusion Models}, 
      author={Felix Krause and Stefan Andreas Baumann and Johannes Schusterbauer and Olga Grebenkova and Ming Gui and Vincent Tao Hu and Björn Ommer},
      year={2026},
      eprint={2601.01608},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2601.01608}, 
}
      </code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a
                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                            You are free to borrow the source code of this website, we just ask that you link back to
                            this page in the
                            footer. <br> This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>
